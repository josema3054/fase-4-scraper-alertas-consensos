"""
Servicio de Background para Scrapers Autom√°ticos
Ejecuta scrapers programados y env√≠a alertas
"""

import asyncio
import schedule
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, List
import logging
from pathlib import Path

from src.database.data_manager import data_manager, ScraperProgramado
from src.scraper.mlb_selenium_scraper import MLBSeleniumScraper
from src.notifications.telegram_bot import TelegramNotifier
from src.utils.logger import setup_logger

class ScrapingBackgroundService:
    """Servicio que maneja la ejecuci√≥n autom√°tica de scrapers"""
    
    def __init__(self):
        self.logger = setup_logger(__name__)
        self.is_running = False
        self.scraper = MLBSeleniumScraper()
        self.telegram_bot = None  # Se inicializa si est√° configurado
        self.stats = {
            'scrapers_ejecutados_hoy': 0,
            'ultima_ejecucion': None,
            'errores_hoy': 0,
            'servicio_iniciado_en': datetime.now().isoformat()
        }
        
        # Configurar Telegram si est√° disponible
        self._init_telegram()
        
        self.logger.info("üöÄ ScrapingBackgroundService inicializado")
    
    def _init_telegram(self):
        """Inicializa bot de Telegram si est√° configurado"""
        try:
            # Inicializar con configuraci√≥n b√°sica por ahora
            self.telegram_bot = TelegramNotifier(
                token="dummy_token",  # Reemplazar con token real
                chat_ids=[]  # Lista de chat IDs
            )
            self.logger.info("üì± Bot de Telegram inicializado (modo desarrollo)")
        except Exception as e:
            self.logger.error(f"‚ùå Error inicializando Telegram: {e}")
            self.telegram_bot = None
    
    def start_service(self):
        """Inicia el servicio en background"""
        if self.is_running:
            self.logger.warning("‚ö†Ô∏è El servicio ya est√° ejecut√°ndose")
            return
        
        self.is_running = True
        self.logger.info("üü¢ Iniciando servicio de scrapers autom√°ticos...")
        
        # Programar verificaciones cada minuto
        schedule.every(1).minutes.do(self._verificar_scrapers_pendientes)
        
        # Programar limpieza diaria a las 2:00 AM
        schedule.every().day.at("02:00").do(self._limpieza_diaria)
        
        # Programar reporte diario a las 9:00 AM
        schedule.every().day.at("09:00").do(self._enviar_reporte_diario)
        
        # Ejecutar en thread separado para no bloquear
        service_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        service_thread.start()
        
        self.logger.info("‚úÖ Servicio de background iniciado correctamente")
        
        # Enviar notificaci√≥n de inicio
        self._enviar_notificacion("üöÄ Sistema de Scrapers Autom√°ticos iniciado", 
                                 "El servicio de background est√° activo y monitoreando scrapers programados.")
    
    def stop_service(self):
        """Detiene el servicio"""
        self.is_running = False
        schedule.clear()
        self.logger.info("üî¥ Servicio de scrapers autom√°ticos detenido")
        
        self._enviar_notificacion("üõë Servicio Detenido", 
                                 "El servicio de scrapers autom√°ticos ha sido detenido.")
    
    def _run_scheduler(self):
        """Ejecuta el scheduler en un loop continuo"""
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(30)  # Verificar cada 30 segundos
            except Exception as e:
                self.logger.error(f"‚ùå Error en scheduler: {e}")
                time.sleep(60)  # Esperar m√°s tiempo si hay error
    
    def _verificar_scrapers_pendientes(self):
        """Verifica si hay scrapers que deben ejecutarse"""
        try:
            scrapers_programados = data_manager.obtener_scrapers_programados(solo_activos=True)
            ahora = datetime.now()
            
            for scraper in scrapers_programados:
                if self._debe_ejecutar_scraper(scraper, ahora):
                    self.logger.info(f"üéØ Ejecutando scraper: {scraper.partido_id}")
                    self._ejecutar_scraper_automatico(scraper)
                    
        except Exception as e:
            self.logger.error(f"‚ùå Error verificando scrapers: {e}")
    
    def _debe_ejecutar_scraper(self, scraper: ScraperProgramado, ahora: datetime) -> bool:
        """Determina si un scraper debe ejecutarse ahora"""
        try:
            # Parsear fecha y hora del partido
            fecha_str = scraper.fecha_partido  # "2025-01-21"
            hora_str = scraper.hora_partido    # "7:10 pm ET"
            
            if not fecha_str or not hora_str:
                return False
            
            # Convertir hora del partido a datetime
            # Simplificado: asumir que es para hoy y convertir PM/AM
            from datetime import datetime
            import re
            
            hora_match = re.search(r'(\d{1,2}):(\d{2})\s*(am|pm)', hora_str, re.IGNORECASE)
            if not hora_match:
                return False
            
            hora = int(hora_match.group(1))
            minuto = int(hora_match.group(2))
            periodo = hora_match.group(3).lower()
            
            if periodo == 'pm' and hora != 12:
                hora += 12
            elif periodo == 'am' and hora == 12:
                hora = 0
            
            # Crear datetime del partido
            try:
                fecha_partido = datetime.strptime(fecha_str, '%Y-%m-%d').date()
                datetime_partido = datetime.combine(fecha_partido, datetime.min.time().replace(hour=hora, minute=minuto))
            except:
                # Si no se puede parsear la fecha, usar hoy
                datetime_partido = datetime.now().replace(hour=hora, minute=minuto, second=0, microsecond=0)
            
            # Calcular cu√°ndo ejecutar (15 minutos antes)
            momento_ejecucion = datetime_partido - timedelta(minutes=15)
            
            # Verificar si es el momento (con ventana de 2 minutos)
            diferencia = abs((ahora - momento_ejecucion).total_seconds())
            
            return diferencia <= 120  # Dentro de 2 minutos
            
        except Exception as e:
            self.logger.error(f"‚ùå Error evaluando tiempo de scraper {scraper.id}: {e}")
            return False
    
    def _ejecutar_scraper_automatico(self, scraper: ScraperProgramado):
        """Ejecuta un scraper autom√°tico espec√≠fico"""
        try:
            self.logger.info(f"ü§ñ Ejecutando scraper autom√°tico: {scraper.visitante} @ {scraper.local}")
            
            # Marcar como en proceso
            data_manager.actualizar_estado_scraper(scraper.id, "ejecutando")
            
            # Ejecutar scraper
            inicio = time.time()
            resultados = self.scraper.scrape_mlb_consensus()
            duracion = time.time() - inicio
            
            if resultados:
                # Buscar el partido espec√≠fico en los resultados
                partido_encontrado = None
                for resultado in resultados:
                    if (resultado.get('visitante', '').lower() == scraper.visitante.lower() and
                        resultado.get('local', '').lower() == scraper.local.lower()):
                        partido_encontrado = resultado
                        break
                
                if partido_encontrado:
                    # Verificar si hubo cambios significativos
                    cambios = self._detectar_cambios_consenso(scraper, partido_encontrado)
                    
                    # Guardar resultado
                    resultado_completo = {
                        'datos': partido_encontrado,
                        'duracion': duracion,
                        'timestamp': datetime.now().isoformat(),
                        'cambios_detectados': cambios
                    }
                    
                    data_manager.actualizar_estado_scraper(scraper.id, "ejecutado", resultado_completo)
                    
                    # Enviar alerta si hay cambios significativos
                    if cambios:
                        self._enviar_alerta_cambios(scraper, partido_encontrado, cambios)
                    
                    self.stats['scrapers_ejecutados_hoy'] += 1
                    self.stats['ultima_ejecucion'] = datetime.now().isoformat()
                    
                    self.logger.info(f"‚úÖ Scraper ejecutado exitosamente: {scraper.partido_id}")
                else:
                    # No se encontr√≥ el partido espec√≠fico
                    data_manager.actualizar_estado_scraper(scraper.id, "error", 
                                                         {"error": "Partido no encontrado en resultados"})
                    self.stats['errores_hoy'] += 1
                    self.logger.warning(f"‚ö†Ô∏è Partido no encontrado: {scraper.partido_id}")
            else:
                # Error en scraping
                data_manager.actualizar_estado_scraper(scraper.id, "error", 
                                                     {"error": "No se obtuvieron resultados"})
                self.stats['errores_hoy'] += 1
                self.logger.error(f"‚ùå Error en scraping para: {scraper.partido_id}")
                
        except Exception as e:
            self.logger.error(f"‚ùå Error ejecutando scraper {scraper.id}: {e}")
            data_manager.actualizar_estado_scraper(scraper.id, "error", {"error": str(e)})
            self.stats['errores_hoy'] += 1
    
    def _detectar_cambios_consenso(self, scraper: ScraperProgramado, nuevos_datos: Dict) -> List[Dict]:
        """Detecta cambios significativos en el consenso"""
        cambios = []
        
        try:
            # Comparar porcentajes (extraer n√∫meros de strings como "65%")
            consenso_anterior = scraper.consenso_actual
            over_actual = float(nuevos_datos.get('over_percentage', '0').replace('%', ''))
            under_actual = float(nuevos_datos.get('under_percentage', '0').replace('%', ''))
            
            # Determinar direcci√≥n actual
            direccion_actual = "OVER" if over_actual > under_actual else "UNDER"
            porcentaje_actual = max(over_actual, under_actual)
            
            # Extraer porcentaje anterior (simple)
            import re
            match = re.search(r'(\d+)%', consenso_anterior)
            porcentaje_anterior = float(match.group(1)) if match else 50
            
            # Detectar cambio significativo (>5%)
            diferencia = abs(porcentaje_actual - porcentaje_anterior)
            if diferencia >= 5:
                cambios.append({
                    'tipo': 'cambio_porcentaje',
                    'anterior': f"{porcentaje_anterior}%",
                    'actual': f"{porcentaje_actual}%",
                    'diferencia': f"+{diferencia}%" if porcentaje_actual > porcentaje_anterior else f"-{diferencia}%"
                })
            
            # Detectar cambio de direcci√≥n
            if "OVER" in consenso_anterior and direccion_actual == "UNDER":
                cambios.append({
                    'tipo': 'cambio_direccion',
                    'anterior': 'OVER',
                    'actual': 'UNDER'
                })
            elif "UNDER" in consenso_anterior and direccion_actual == "OVER":
                cambios.append({
                    'tipo': 'cambio_direccion', 
                    'anterior': 'UNDER',
                    'actual': 'OVER'
                })
            
        except Exception as e:
            self.logger.error(f"Error detectando cambios: {e}")
        
        return cambios
    
    def _enviar_alerta_cambios(self, scraper: ScraperProgramado, datos: Dict, cambios: List[Dict]):
        """Env√≠a alerta por cambios significativos"""
        mensaje = f"üö® **CAMBIO DETECTADO** üö®\n\n"
        mensaje += f"üèüÔ∏è **Partido:** {scraper.visitante} @ {scraper.local}\n"
        mensaje += f"‚è∞ **Hora:** {scraper.hora_partido}\n\n"
        
        for cambio in cambios:
            if cambio['tipo'] == 'cambio_porcentaje':
                mensaje += f"üìä **Consenso:** {cambio['anterior']} ‚Üí {cambio['actual']} ({cambio['diferencia']})\n"
            elif cambio['tipo'] == 'cambio_direccion':
                mensaje += f"üîÑ **Direcci√≥n:** {cambio['anterior']} ‚Üí {cambio['actual']}\n"
        
        mensaje += f"\nüí° **Estado Actual:**\n"
        mensaje += f"  OVER: {datos.get('over_percentage', 'N/A')}\n"
        mensaje += f"  UNDER: {datos.get('under_percentage', 'N/A')}\n"
        mensaje += f"  Expertos: {datos.get('num_experts', 'N/A')}\n"
        
        self._enviar_notificacion("üö® Cambio de Consenso Detectado", mensaje)
    
    def _enviar_notificacion(self, titulo: str, mensaje: str):
        """Env√≠a notificaci√≥n por Telegram (si est√° configurado)"""
        if self.telegram_bot and self.telegram_bot.chat_ids:
            try:
                # Para el desarrollo, solo hacer log
                self.logger.info(f"üì± [TELEGRAM] {titulo}: {mensaje}")
                # Aqu√≠ ir√≠a: await self.telegram_bot.send_alert_message(f"{titulo}\n\n{mensaje}")
            except Exception as e:
                self.logger.error(f"‚ùå Error enviando notificaci√≥n Telegram: {e}")
        else:
            self.logger.info(f"üì± [LOG] {titulo}: {mensaje}")
    
    def _limpieza_diaria(self):
        """Limpieza diaria de datos antiguos"""
        try:
            self.logger.info("üßπ Ejecutando limpieza diaria...")
            data_manager.limpiar_datos_antiguos(dias=7)
            
            # Resetear estad√≠sticas del d√≠a
            self.stats['scrapers_ejecutados_hoy'] = 0
            self.stats['errores_hoy'] = 0
            
            self.logger.info("‚úÖ Limpieza diaria completada")
            
        except Exception as e:
            self.logger.error(f"‚ùå Error en limpieza diaria: {e}")
    
    def _enviar_reporte_diario(self):
        """Env√≠a reporte diario de actividad"""
        try:
            stats = data_manager.obtener_estadisticas_hoy()
            
            reporte = f"üìä **REPORTE DIARIO** - {stats['fecha']}\n\n"
            reporte += f"ü§ñ **Scrapers Autom√°ticos:**\n"
            reporte += f"  ‚Ä¢ Programados: {stats['scrapers_automaticos']['total_programados']}\n"
            reporte += f"  ‚Ä¢ Ejecutados: {stats['scrapers_automaticos']['ejecutados']}\n" 
            reporte += f"  ‚Ä¢ Pendientes: {stats['scrapers_automaticos']['pendientes']}\n\n"
            
            reporte += f"üìä **Sesiones de Scraping:**\n"
            reporte += f"  ‚Ä¢ Total: {stats['sesiones_scraping']['total']}\n"
            reporte += f"  ‚Ä¢ Promedio partidos: {stats['sesiones_scraping']['promedio_partidos']}\n"
            reporte += f"  ‚Ä¢ Duraci√≥n promedio: {stats['sesiones_scraping']['duracion_promedio']}s\n\n"
            
            reporte += f"üìà **Servicio:**\n"
            reporte += f"  ‚Ä¢ Ejecutados hoy: {self.stats['scrapers_ejecutados_hoy']}\n"
            reporte += f"  ‚Ä¢ Errores: {self.stats['errores_hoy']}\n"
            reporte += f"  ‚Ä¢ √öltima ejecuci√≥n: {self.stats['ultima_ejecucion'] or 'Ninguna'}\n"
            
            self._enviar_notificacion("üìä Reporte Diario", reporte)
            
        except Exception as e:
            self.logger.error(f"‚ùå Error generando reporte diario: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """Obtiene el estado actual del servicio"""
        return {
            'servicio_activo': self.is_running,
            'telegram_configurado': self.telegram_bot is not None,
            'estadisticas': self.stats,
            'scrapers_pendientes': len(data_manager.obtener_scrapers_programados(solo_activos=True))
        }

# Instancia global del servicio
background_service = ScrapingBackgroundService()
